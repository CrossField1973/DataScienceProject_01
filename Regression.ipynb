{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhaltsverzeichnis\n",
    "1. Bibliotheken importieren\n",
    "1. Anomalien entfernen und Feature Engeneering\n",
    "1. Merkmale auswählen\n",
    "1. Regression\n",
    "1. Modelle Bewerten\n",
    "1. Erklärung Lineare Regression\n",
    "1. Evaluation GBT\n",
    "1. Unabhängige Validierung\n",
    "1. Anleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Um das Model zu testen, ändern Sie den Dateinamen im Code-Teil unter \"8.Unabhängige Validierung\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data Science + Mathe Bibliotheken\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "# Metriken\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "\n",
    "# Validierung\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Modelle\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Warnungen \n",
    "import warnings\n",
    "\n",
    "#define Mape\n",
    "# https://www.statology.org/mape-python/\n",
    "def mean_absolute_percentage_error(actual, pred):\n",
    "    actual, pred = np.reshape(np.array(actual), (-1)), np.reshape(np.array(pred),(-1))\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Anomalien entfernen und Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv('DatenAusgegeben1.2_UTF8_manuell.csv', sep=\";\", keep_default_na=False)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bereinigung und Feature Engeneering\n",
    "\n",
    "# für €/qm² für besseren Vergleich der Daten\n",
    "housing_data[\"Preisproqm\"] = housing_data[\"Preis\"]/housing_data[\"Wohnflaeche in qm\"]\n",
    "\n",
    "# Monate seit 2136\n",
    "housing_data[\"Monate\"] = (housing_data[\"Verkaufsjahr\"]-2136)*12 + housing_data[\"Verkaufsmonat\"] -1\n",
    "\n",
    "# Werte der Heizungsqualitaet in Zahlen umwandeln\n",
    "housing_data[\"Heizungsqualitaet\"] = [1 if x==\"Schl\" else 2 if x==\"Ud\" else 3 if x==\"Ty\" else 4 if x==\"Gut\" else 5 for x in housing_data[\"Heizungsqualitaet\"]]\n",
    "\n",
    "# Zustand, 1-10 wird auf 1-5 gemapt, das ist zwar ein bisschen ungenauer, aber einfacher zu vergleichen\n",
    "housing_data[\"Zustandf\"] = [int(x/2) + x%2 for x in housing_data[\"Zustand\"]]\n",
    "\n",
    "# Alle Zustände werden von 1...X auf 0....X-1 geschoben\n",
    "housing_data[\"HeizungsqualitaetN\"] = [ x-1 for x in housing_data[\"Heizungsqualitaet\"]]\n",
    "housing_data[\"ZustandN\"] = [ x-1 for x in housing_data[\"Zustandf\"]]\n",
    "housing_data[\"FassadeN\"] = [ x-1 for x in housing_data[\"Zustand Fassade\"]]\n",
    "housing_data[\"KuecheN\"] = [ x-1 for x in housing_data[\"Kuechenqualitaet\"]]\n",
    "\n",
    "# Klimaanlage Ja/Nein  -> 1/0\n",
    "housing_data[\"Klimaanlage\"] = [1 if x == \"Y\" else 0 for x in housing_data[\"Klimaanlage\"]]\n",
    "\n",
    "# Besonders Große Daten beim Preis + Wohnfläche in qm rausschmeißen\n",
    "max_value = housing_data[\"Preis\"].unique()[-1:][0]\n",
    "housing_data[housing_data[\"Preis\"] != max_value]\n",
    "\n",
    "max_value = housing_data[\"Wohnflaeche in qm\"].unique()[-1:][0]\n",
    "housing_data[housing_data[\"Wohnflaeche in qm\"] != max_value]\n",
    "\n",
    "max_value = housing_data[\"Grundstueck in qm\"].unique()[-2:][0]\n",
    "housing_data[housing_data[\"Grundstueck in qm\"] != max_value]\n",
    "\n",
    "\n",
    "# NA in Garage Typ wird zu \"Keine Garage\"\n",
    "housing_data[\"Garage Typ\"] = ['keine Garage' if x=='NA' else x for x in housing_data[\"Garage Typ\"]]\n",
    "\n",
    "\n",
    "print(housing_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merkmale auswählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X und Y aus dem Datenset auslesen\n",
    "\n",
    "# Zu testende Merkmale festlegen (X)\n",
    "features = [ \"Grundstueck in qm\", \"Wohnflaeche in qm\",\"ZustandN\",\"KuecheN\", \"HeizungsqualitaetN\", \"FassadeN\",\n",
    "            \"Klimaanlage\", \"Gebaut\", \"Garagenkapazitaet\"]\n",
    "# Räume \n",
    "# Preis (Y)\n",
    "predict= \"Preis\"\n",
    "\n",
    "X = {}\n",
    "for feature in features:\n",
    "    X[feature] = housing_data[feature]\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "Y = pd.DataFrame(housing_data[predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finden der Hyperparameter für GBT\n",
    "\n",
    "def info(data):\n",
    "    best = {}\n",
    "    for i in score_types_test:\n",
    "        # Beste Scores der Modelle  auswählen\n",
    "        if i == \"r2score\":\n",
    "            best[i] = np.sort(data[i])[-1]\n",
    "        else:\n",
    "            best[i] = np.sort(data[i])[0]\n",
    "    return best\n",
    "        \n",
    "\n",
    "def score_model_test(curr_model, x_test, y_test,scores):\n",
    "    scores[\"r2score\"].append(r2_score(curr_model.predict(x_test), y_test))\n",
    "    scores[\"mse\"].append(mean_squared_error(curr_model.predict(x_test), y_test))\n",
    "    scores[\"rmse\"].append(mean_squared_error(curr_model.predict(x_test), y_test, squared = False))\n",
    "    scores[\"mape\"].append(mean_absolute_percentage_error(curr_model.predict(x_test), y_test))\n",
    "    scores[\"max\"].append(max_error(curr_model.predict(x_test), y_test))\n",
    "    return\n",
    "\n",
    "def work(depth, estimators, learn,data):\n",
    "    \n",
    "    scores = {\"r2score\":[], \"mse\":[], \"rmse\":[], \"mape\":[], \"max\":[]}\n",
    "    #Initialisierung\n",
    "    for k in data:\n",
    "        # Parameter durch probieren herausfinden \n",
    "        curr_model = GradientBoostingRegressor(\n",
    "            max_depth=depth, n_estimators=estimators, learning_rate=learn/100, loss=\"ls\")\n",
    "        \n",
    "        curr_model.fit(k[\"x_poly_train\"], k[\"y_train\"])\n",
    "        score_model_test(curr_model, k[\"x_poly_test\"], k[\"y_test\"], scores)\n",
    "    \n",
    "    return scores\n",
    "    \n",
    "def update(best, best2):\n",
    "    if len(best) == 0:\n",
    "        #Start\n",
    "        for i in best2:\n",
    "            best[i] = {\"value\": best2[i], \"depth\" : depth, \"n_est\": n_est, \"learn\":learn}\n",
    "    else:\n",
    "        for i in best:\n",
    "            if i == \"r2score\" and best[i][\"value\"] < best2[i]:\n",
    "            # R2, der muss höher sein\n",
    "                best[i] = {\"value\": best2[i], \"depth\" : depth, \"n_est\": n_est, \"learn\":learn} \n",
    "            elif best[i][\"value\"] > best2[i]:\n",
    "                # sonst müssen sie kleiner sein\n",
    "                best[i] = {\"value\": best2[i], \"depth\" : depth, \"n_est\": n_est, \"learn\":learn} \n",
    "    return\n",
    "\n",
    "def init():\n",
    "    # Daten vorbereiten\n",
    "    data = []\n",
    "    Kfold = KFold(n_splits=10, random_state=89)\n",
    "    kfold = Kfold.split(X, Y)\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        poly = PolynomialFeatures(degree=3)\n",
    "        x_train = X.iloc[train, :]\n",
    "        x_test = X.iloc[test, :]\n",
    "        x_poly = poly.fit_transform(x_train)\n",
    "        x_poly_test = poly.fit_transform(x_test)\n",
    "        y_train = Y.iloc[train]\n",
    "        y_test = Y.iloc[test]\n",
    "        data.append({\"x_poly_train\": x_poly, \"x_train\": x_train, \"y_train\": y_train,\n",
    "                     \"x_poly_test\": x_poly_test, \"x_test\": x_test, \"y_test\": y_test})\n",
    "    # Modelle testen\n",
    "    score_types_test = [\"r2score\", \"mse\", \"rmse\", \"mape\", \"max\"]\n",
    "    best = {}\n",
    "    # Start \n",
    "    for depth in range(3,7):\n",
    "        for n_est in range(20,180,20):\n",
    "            for learn in range(1,50,5):\n",
    "                mscores = work(depth,n_est,learn,data)\n",
    "                best2 = info(mscores)\n",
    "                update(best, best2)\n",
    "    print(best)\n",
    "    return\n",
    "\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# K-fache Cross-Validierung, Polynomial Features\n",
    "\n",
    "\n",
    "# Speichert (R2, MSE, RMSE, MAPE, MAX) in  model[score][mtype]..\n",
    "def score_model(curr_model, x_test, y_test, model ,mtype):\n",
    "    \n",
    "    model[\"scores\"][mtype][\"r2score\"].append(r2_score(curr_model.predict(x_test), y_test))\n",
    "    model[\"scores\"][mtype][\"mse\"].append(mean_squared_error(curr_model.predict(x_test), y_test))\n",
    "    model[\"scores\"][mtype][\"rmse\"].append(mean_squared_error(curr_model.predict(x_test), y_test, squared = False))\n",
    "    model[\"scores\"][mtype][\"mape\"].append(mean_absolute_percentage_error(curr_model.predict(x_test), y_test))\n",
    "    model[\"scores\"][mtype][\"max\"].append(max_error(curr_model.predict(x_test), y_test))\n",
    "    return\n",
    "\n",
    "split = 10\n",
    "Kfold = KFold(n_splits=split, random_state=89)\n",
    "kfold = Kfold.split(X, Y)\n",
    "\n",
    "storage_poly = {\"scores\":{}, \"models\" : {}, \"best\" : {}}\n",
    "storage_normal = {\"scores\":{}, \"models\" : {}, \"best\" : {}}\n",
    "storage = {\"data\":[],\"arch_types\": [\"poly\",\"normal\"], \n",
    "           \"types\":[ \"osl\", \"lasso\", \"ridge\", \"gbt\", \"rf\", \"sgd\"], \n",
    "           \"score_types\": [\"r2score\", \"mse\", \"rmse\", \"mape\", \"max\"], \"poly\": storage_poly, \"normal\":storage_normal}\n",
    "\n",
    "#Initialisierung\n",
    "for mtype in storage[\"types\"]:\n",
    "    storage_poly[\"scores\"][mtype] = {}\n",
    "    storage_normal[\"scores\"][mtype] = {}\n",
    "    for i in storage[\"score_types\"]:\n",
    "        storage_poly[\"scores\"][mtype][i] = []\n",
    "        storage_normal[\"scores\"][mtype][i] = []\n",
    "        \n",
    "    storage_poly[\"models\"][mtype] = []\n",
    "    storage_normal[\"models\"][mtype] = []\n",
    "    \n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    # Daten vorbereiten und für später speichern\n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    x_train = X.iloc[train, :]\n",
    "    x_test = X.iloc[test, :]\n",
    "    x_poly = poly.fit_transform(x_train)\n",
    "    x_poly_test = poly.fit_transform(x_test)\n",
    "    y_train = Y.iloc[train]\n",
    "    y_test = Y.iloc[test]\n",
    "    storage[\"data\"].append({\"xpoly\": x_poly, \"x_train\": x_train, \"y_train\": y_train, \n",
    "                          \"x_poly_test\": x_poly_test, \"x_test\": x_test, \"y_test\": y_test})\n",
    "    \n",
    "    # Modelle Testen, dabei sowohl \n",
    "    for arch in storage[\"arch_types\"]:\n",
    "        model = storage[arch]\n",
    "        \n",
    "        # Parameter durch probieren herausgefunden \n",
    "        model[\"models\"][\"osl\"].append(linear_model.LinearRegression(n_jobs=-1))\n",
    "        model[\"models\"][\"lasso\"].append(linear_model.Lasso(alpha=1.5, random_state=404))\n",
    "        model[\"models\"][\"ridge\"].append(linear_model.Ridge(alpha=1.5))\n",
    "        model[\"models\"][\"gbt\"].append(GradientBoostingRegressor(\n",
    "            max_depth=4, n_estimators=100, learning_rate=0.15, loss=\"ls\"))\n",
    "        model[\"models\"][\"rf\"].append(RandomForestRegressor(\n",
    "            max_depth=10, n_estimators=10, criterion=\"mse\",n_jobs=-1,max_features=None))\n",
    "        model[\"models\"][\"sgd\"].append(SGDRegressor())\n",
    "        \n",
    "\n",
    "        #model[\"models\"][\"poly\"].append(poly)\n",
    "        for mtype in storage[\"types\"]:\n",
    "            curr_model = model[\"models\"][mtype][k]\n",
    "            \n",
    "            if arch == \"poly\":\n",
    "                curr_model.fit(x_poly, y_train)\n",
    "                score_model(curr_model, x_poly_test, y_test, model, mtype)\n",
    "                \n",
    "            else:\n",
    "                curr_model.fit(x_train, y_train)\n",
    "                score_model(curr_model, x_test, y_test, model, mtype)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modelle Bewerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Berechnet das beste Model und\n",
    "# R2, MSE, RMSE, MAPE, MAX\n",
    "if \"sgd\" in storage[\"types\"]:\n",
    "            storage[\"types\"].remove(\"sgd\")\n",
    "\n",
    "for arch in storage[\"arch_types\"]:\n",
    "    model = storage[arch]\n",
    "    # Für jeden Modelltyp (pro arch_type) den besten Finden und alle Performancedaten auslesen\n",
    "    for mtype in storage[\"types\"]:\n",
    "        # Bestes Modell nach R2 Wert auswählen\n",
    "        best = model[\"scores\"][mtype][\"r2score\"].index(np.sort(model[\"scores\"][mtype][\"r2score\"])[-1:][0])\n",
    "        model[\"best\"][mtype] = best\n",
    "        \n",
    "        print(arch, mtype)\n",
    "        for i in storage[\"score_types\"]:\n",
    "            mean_score = np.mean(model[\"scores\"][mtype][i])\n",
    "            std_score = np.std(model[\"scores\"][mtype][i])\n",
    "            # bis auf r2 ist kleiner besser\n",
    "            if i == \"r2score\":\n",
    "                max_score = np.sort(model[\"scores\"][mtype][i])[-1]\n",
    "            else:\n",
    "                    max_score = np.sort(model[\"scores\"][mtype][i])[0]\n",
    "            \n",
    "            print(\"%8s von %s:\\t%.4f +- %.3f (%.4f best)\" % (i,mtype, mean_score, std_score, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo -> WErte beschreiben, kurz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Beispielgrafiken -> Entwicklung der Werte\n",
    "\n",
    "def print_graphic(position, arch):\n",
    "    model = storage[arch]\n",
    "    # Eine Grafikreihe zeichnen\n",
    "    mtype = storage[\"types\"][i]\n",
    "    best_model = model[\"models\"][mtype][model[\"best\"][mtype]]\n",
    "    \n",
    "    x_test = storage[\"data\"][model[\"best\"][mtype]][\"x_test\"]\n",
    "    if arch == \"poly\":\n",
    "        # Andere Eingaben, wenn Polynomielle Modelle verglichen werden.\n",
    "        x_test = storage[\"data\"][model[\"best\"][mtype]][\"x_poly_test\"]\n",
    "        \n",
    "    y_test = storage[\"data\"][model[\"best\"][mtype]][\"y_test\"]\n",
    "    pred_y = best_model.predict(x_test)\n",
    "    # Abweichung in Prozent in Grafik packen\n",
    "    # (1. Grafik)\n",
    "    \n",
    "    ax = fig.add_subplot(2,len(storage[\"types\"]), position+1)\n",
    "    plt.sca(ax)\n",
    "    plt.hist(np.reshape(pred_y,(-1,1)) / np.reshape(y_test,(-1,1)))\n",
    "    plt.xlim(0.25,1.75)\n",
    "    plt.ylim(0,120)\n",
    "    plt.title(storage[\"types\"][position])\n",
    "    plt.xlabel(\"Verhältnis der Werte\")\n",
    "    plt.ylabel(\"Anzahl\")\n",
    "    if position != 0:\n",
    "        plt.yticks([])\n",
    "    \n",
    "    \n",
    "    # Beispielvorhersage für ein Haus\n",
    "    # (2. Grafik)\n",
    "    x = np.arange(100,200,1)\n",
    "    y = []\n",
    "    for c in range(5): # 5 Zustände\n",
    "        y.append([])\n",
    "        for v in x: # für jeden x-Wert ein y-Wert berechnen\n",
    "            \n",
    "            #[ \"Grundstueck in qm\", \"Wohnflaeche in qm\",\"ZustandN\",\"KuecheN\", \"HeizungsqualitaetN\", \"FassadeN\",\n",
    "            #\"Klimaanlage\", \"Gebaut\", \"Garagenkapazitaet\"]\n",
    "            test_data = [[800 + 3*v, v, c, c, c, c, int(c/3), 2030, 2]]\n",
    "            \n",
    "            if arch == \"poly\":\n",
    "                y[c].append(best_model.predict(poly.fit_transform(test_data))[0])\n",
    "            else:\n",
    "                y[c].append(best_model.predict(test_data)[0])\n",
    "    \n",
    "    #Plot\n",
    "    ax = fig.add_subplot(2,len(storage[\"types\"]), position+1+len(storage[\"types\"]))\n",
    "    plt.sca(ax)\n",
    "    plt.xlim(100,200)\n",
    "    plt.plot(x, y[0], c=\"yellow\", label=\"1\")     \n",
    "    plt.plot(x, y[1], c=\"orange\", label=\"2\")\n",
    "    plt.plot(x, y[2], c=\"red\", label=\"3\")\n",
    "    plt.plot(x, y[3], c=\"purple\" ,label=\"4\")\n",
    "    plt.plot(x, y[4], c=\"blue\" ,label=\"5\")\n",
    "    plt.legend(loc=\"upper left\", ncol=2)\n",
    "    plt.title(storage[\"types\"][position])\n",
    "    plt.xlabel(\"Wohnflaeche in Qm\")\n",
    "    plt.ylabel(\"Preis\")\n",
    "    if position != 0:\n",
    "        plt.yticks([])\n",
    "    return\n",
    "\n",
    "# Nachdem sgd zu schlecht ist, wird es zur Evaluation entfernt!\n",
    "\n",
    "\n",
    "# \n",
    "for arch in storage[\"arch_types\"]:\n",
    "    \n",
    "    # Grafiken vorbereiten\n",
    "    fig, big_axes = plt.subplots( figsize=(15, 10) , nrows=2, ncols=1)\n",
    "\n",
    "    big_axes[0].set_title(\"Verhältnis der vorhergesagten und wirklichen Preise\",fontsize=16, pad=25)\n",
    "    big_axes[0].tick_params(labelcolor=(1.,1.,1., 0.0), top='off', bottom='off', left='off', right='off')\n",
    "    big_axes[0]._frameon = False\n",
    "\n",
    "    big_axes[1].set_title(\"Preisentwickung bei verschiedenen Hauszuständen\",fontsize=16,pad=25)\n",
    "    big_axes[1].tick_params(labelcolor=(1.,1.,1., 0.0), top='off', bottom='off', left='off', right='off')\n",
    "    big_axes[1]._frameon = False\n",
    "    \n",
    "    #Grafiken zeichnen\n",
    "    for i in range(len(storage[\"types\"])):\n",
    "        print_graphic(i,arch)\n",
    "        \n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie in den Graphen zu sehen ist, entspricht das Verhältnis der vorhergesagten und wahren Preisen einer Gaussverteilung, was zu erwarten war. Nachdem der Stochastic Gradiend Descend zu schlechte Werte vorhergesagt hat, wurde in der Analyse nicht weiter betrachtet. Ein Grund dafür kann sein, dass der SGD für besonders große Datenmengen gedacht ist. Desweiteren kommt die Ordinary Squared Loss und die ridge-Regression nicht mit einer Input-Transformation auf ein Polynom #TODO 4. Grades zurecht, deren Werte sind bei linearen Eingaben deutlich besser.    \n",
    "In der zweiten Graphenreihe wurde ein fiktives Haus erstellt, dessen Zustand und Wohnfläche variabel ist. In den Graphiken ist gut zusehen, dass es einen großen preislichen Unterschied zwischen den einzelnen Zuständen gibt. Sehr gute Häuser sind deutlich teurer. In der Ordinarily Squared Loss- und Ridge-Regression werden Häuser mit sehr niedrigen Qualität bei größer werdender Wohnfläche billiger, was entweder auf ein schlechtes Modell oder auf schlechte Testdaten hindeutet. Die Relation von Grundstücksfläche = 800 + 3 * Wohnfläche kann auch Einfluss auf die Qualität der Vorhersage nehmen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erklärung Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ein leicht Verständliches Modell ist die Ordinary Squared Loss-Regression mit linearen Eingaben. \n",
    "Unten wird die Formel ausgegeben, mit der Vorsagen getroffen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = storage[\"normal\"][\"osl\"][storage[\"normal\"][\"best\"][\"osl\"]]\n",
    "coefs = linreg.coef_\n",
    "features\n",
    "formula = \"y(X) = \"\n",
    "for i in range(len(features)):\n",
    "    fomula += \" %d * \\\"%s\\\" +\" % (coefs[i], features[i])\n",
    "formula = formula[:-1]\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation GBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Projekt wurden folgende Regressionen getestet: \n",
    "* Ordinary Squared Loss \n",
    "* Lasso \n",
    "* Ridge \n",
    "* Gradient Boosting Trees \n",
    "* Random Forest<br>\n",
    "<br>\n",
    "Die Modelle wurden mit 1600 Wohnungsdatensätzen trainiert. Diese Merkmale wurden als Eingabe verwendet:\n",
    "* Grundstück in qm \n",
    "* Wohnfläche in qm\n",
    "* Zustand         (Nullbasiert)\n",
    "* Zustand Kueche  (Nullbasiert)\n",
    "* Zustand Heizung (Nullbasiert)\n",
    "* Zustand Fassade (Nullbasiert)\n",
    "* Klimaanlage\n",
    "* Baujahr\n",
    "* Garagenkapazität\n",
    "* Anzahl Räume\n",
    "<br>\n",
    "<br>\n",
    "Mit diesen Merkmalen wird von den verwendeten Modellen der Preis in GC Dollar vorhergesagt.<br>\n",
    "<br>\n",
    "Bei diesem Projekt hat sich Gradient Boosting Trees als bestes Model herausgestellt.<br>\n",
    "Mit einem maximalen R2-Wert von 0,884 hat diesen Model nach Random Forest (0,894) und Lasso (0,889) den dritthöchsten Wert in den zehn Trainingsdurchläufen (K-fache Kreuz-Validierung) erreicht.<br>\n",
    "Jedoch hatte Gradient Boosting Trees die geringste Standardabweichung im R2-Wert (+- 0,031) in allen Durchgängen und damit auch den besten durchschnittlichen R2-Wert (0,837).<br>\n",
    "Mit einem Root Mean Square Error von 20.190,43, liegt das Modell mit seinen Prognosen im Mittel ca. 20.000 GC Dollar daneben. <br>\n",
    "Bei einem Maximum Error von 65422,66 liegt die größte Abweichung im Test bei ca. 65.000 GC Dollar. <br>\n",
    "Bei beiden dieser Metriken ist Gradient Boosting Trees der klare Sieger. <br>\n",
    "Es muss jedoch beachtet werden, dass das Model mit 38,59 einen sehr hohen Mean Absolute Percentage Error hat.\n",
    "#TODO Gradiend boosting tree ausreißer\n",
    "#TOdo Grafik oben bewerten\n",
    "\n",
    "Summary (3 - 5 Punkte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Unabhängige Validierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "housing_data2 = pd.read_csv('DatenAusgegeben1.2_UTF8_manuell.csv', sep=\";\", keep_default_na=False)\n",
    "\n",
    "\n",
    "housing_data2[\"Preisproqm\"] = housing_data2[\"Preis\"]/housing_data2[\"Wohnflaeche in qm\"]\n",
    "\n",
    "# Monate seit 2136\n",
    "housing_data2[\"Monate\"] = (housing_data2[\"Verkaufsjahr\"]-2136)*12 + housing_data2[\"Verkaufsmonat\"] -1\n",
    "\n",
    "# Werte der Heizungsqualitaet in Zahlen umwandeln\n",
    "housing_data2[\"Heizungsqualitaet\"] = [1 if x==\"Schl\" else 2 if x==\"Ud\" else 3 if x==\"Ty\" else 4 if x==\"Gut\" else 5 for x in housing_data2[\"Heizungsqualitaet\"]]\n",
    "\n",
    "# Zustand, 1-10 wird auf 1-5 gemapt, das ist zwar ein bisschen ungenauer, aber einfacher zu vergleichen\n",
    "housing_data2[\"Zustandf\"] = [int(x/2) + x%2 for x in housing_data2[\"Zustand\"]]\n",
    "\n",
    "# Alle Zustände werden von 1...X auf 0....X-1 geschoben\n",
    "housing_data2[\"HeizungsqualitaetN\"] = [ x-1 for x in housing_data2[\"Heizungsqualitaet\"]]\n",
    "housing_data2[\"ZustandN\"] = [ x-1 for x in housing_data2[\"Zustandf\"]]\n",
    "housing_data2[\"FassadeN\"] = [ x-1 for x in housing_data2[\"Zustand Fassade\"]]\n",
    "housing_data2[\"KuecheN\"] = [ x-1 for x in housing_data2[\"Kuechenqualitaet\"]]\n",
    "\n",
    "# Klimaanlage Ja/Nein  -> 1/0\n",
    "housing_data2[\"Klimaanlage\"] = [1 if x == \"Y\" else 0 for x in housing_data2[\"Klimaanlage\"]]\n",
    "\n",
    "# NA in Garage Typ wird zu \"Keine Garage\"\n",
    "housing_data2[\"Garage Typ\"] = ['keine Garage' if x=='NA' else x for x in housing_data2[\"Garage Typ\"]]\n",
    "\n",
    "\n",
    "X2 = {}\n",
    "for feature in features:\n",
    "    X2[feature] = housing_data2[feature]\n",
    "X2 = pd.DataFrame(X)\n",
    "\n",
    "Y2 = pd.DataFrame(housing_data2[predict])\n",
    "\n",
    "x2_poly = poly.fit_transform(X2.iloc[train, :])\n",
    "poly.fit(X2.iloc[train, :], Y2.iloc[train])\n",
    "x2_poly_test = poly.fit_transform(X2.iloc[test, :])\n",
    "\n",
    "# R2, MSE, RMSE, MAPE, MAX\n",
    "test_model = model[\"models\"][\"gbt\"][model[\"best\"][\"gbt\"]]\n",
    "x_test = model[\"data\"][model[\"best\"][\"gbt\"]][\"x_poly_test\"]\n",
    "y_test = model[\"data\"][model[\"best\"][\"gbt\"]][\"y_test\"]\n",
    "\n",
    "r2_test = round(r2_score(test_model.predict(x_test), y_test), 2)\n",
    "mse_test = round(mean_squared_error(test_model.predict(x_test), y_test), 2)\n",
    "rmse_test = round(mean_squared_error(test_model.predict(x_test), y_test, squared=False), 2)\n",
    "mape_test = round(mean_absolute_percentage_error(test_model.predict(x_test), y_test), 2)\n",
    "max_test = round(max_error(test_model.predict(x_test), y_test), 2)\n",
    "\n",
    "print(\"R2 Wert:\", r2_test)\n",
    "print(\"Mean Squared Error Wert:\", mse_test)\n",
    "print(\"Root Mean Square Error Wert:\", rmse_test)\n",
    "print(\"Mean Absolute Percentage Error Wert:\", mape_test)\n",
    "print(\"Maximum Error Wert:\", max_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Anleitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mpredict(data, renovation=None):\n",
    "    mtyp = \"gbt\"\n",
    "    \n",
    "    dinput = [\"Grundstück\", \"Wohnraum\", \"Zustand\", \"Küche\", \"Klimaanlage\", \"Fassade\", \"Gebaut\", \"Garagenkapazitaet\", \"Heizungsqualitaet\", \"Räume\"]\n",
    "    \n",
    "    curr_model = model[\"models\"][mtyp][model[\"best\"][mtyp]]\n",
    "    # Eingaben überprüfen\n",
    "    if len(data) != len(dinput):\n",
    "        print(\"Eingaben überprüfen: %d Elemente erwartet, aber nur %d Elemente vorhanden!\" % \n",
    "              (len(dinput), len(data)))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    pred_y = curr_model.predict(poly.fit_transform([data]))[0]\n",
    "    print(\"Vorhergesagter Preis: %i€\" % int(pred_y))\n",
    "    \n",
    "    \n",
    "    if renovation != None:\n",
    "        new_data = data.copy()\n",
    "        # neue Daten laden\n",
    "        for ren_data in renovation.keys():\n",
    "            if ren_data not in dinput:\n",
    "                print(\"Unerkannte Eingabe, Renovation überprüfen\")\n",
    "                return;\n",
    "            index = dinput.index(ren_data)\n",
    "            new_data[index] = renovation[ren_data]\n",
    "        \n",
    "        # Evaluieren\n",
    "        pred_y_new = curr_model.predict(poly.fit_transform([new_data]))[0]\n",
    "        print(\"Vorhergesagter Wert nach Renovation: %d€, Differenz: %d€\" % (pred_y_new, pred_y_new - pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand der vorhandenen Daten wurde ein Modell entwickelt, mit dem der preisliche Aufwand von Renovationen mit der Wertsteigerung der Immobilie verglichen werden kann. Für diese Aufgabe wurden Modelle auf 1600 Datensätzen trainiert, getestet und die Besten für eine weitere Untersuchung ausgewählt. Das beste Modell war ein Gradiend Boosting Tree (GBT) mit einem R2-Wert von 0.88 #TODO, ist das noch richtig?\n",
    "Das Modell bietet herausragende Vorhersagegenauigkeit für Häuser im Preisbereich von 100.000 bis 500.000 GC Dollar. Sollten Werte getestet werden, die außerhalb dieses Bereichs liegen, \n",
    "\n",
    "werden zwar immernoch gute Preisvorschläge generiert, ihre Richtigkeit kann aber nicht mehr garantiert werden.\n",
    "\n",
    "Um eine Vorhersage zu erhalten, werden folgende Daten benötigt:\n",
    "- Grundstücksfläche in Qm\n",
    "- Wohnfläche in Qm\n",
    "- Zustand des Hauses (Zahl von 0 - 4)\n",
    "- Zustand der Küche (Zahl von 0 - 4)\n",
    "- Vorhandensein einer Klimaanlage (0: Nein, 1: Ja)\n",
    "- Baujahr\n",
    "- Garagenkapazität\n",
    "- Zustand der Heizung (Zahl von 0 - 4)\n",
    "- Zustand der Fassade (Zahl von 0 - 4)\n",
    "- Anzahl der Räume\n",
    "\n",
    "ein Beispielaufruf kann so aussehen:    \n",
    "daten = [1200,80,4,0,0,4,1,2103,4,4]    \n",
    "renovation =  {\"Küche\": 4, \"Klimaanlage\": 1}  \n",
    "mpredict(daten, renovation) \n",
    "\n",
    "\n",
    "Mit diesem Tool kann nun der Wer der Immobilie nach einer Renovation berechnet werden, indem dem Modell der gewünschte Zielzustand gegeben wird. Das Modell berechnet nun den neuen Verkaufspreis und gibt dazu die Differenz zum jetzigen Preis aus. Mit diesem Preis kann nun die Wirtschaftlichkeit der Renovation geprüft und ein Kaufentscheid gefällt werden. # TODO darüber schauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\"Grundstueck in qm\", \"Wohnflaeche in qm\",\"ZustandN\",\"KuecheN\",\"Klimaanlage\", \"Gebaut\", #\"Garagenkapazitaet\", \"HeizungsqualitaetN\", \"Raeume\"]\n",
    "# Istpreis s Preis nach Renovation\n",
    "daten = [1800,140,4,1,1,4,1,2203,2,4]\n",
    "renovation =  {\"Küche\": 4}\n",
    "mpredict(daten, renovation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
